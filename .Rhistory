while (K > 0 & y < prob_conc(R, p.shape, Q, n.tab, dsct)) {
R <- R + w
K <- K - 1
}
return(c(L,R))
}
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.1, 25)
# Find the bounds of a slice
find_bounds <- function(conc.map, y, p.shape, Q, n.tab, dsct, sl.size, max.size) {
U <- runif(1)
V <- runif(1)
L <- conc.map - sl.size*U
R <- L + sl.size
J <- floor(max.size*V)
K <- (max.size - 1) - J
# Finding left bound
while (J > 0 & y < prob_conc(L, p.shape, Q, n.tab, dsct)) {
L <- L - sl.size
J <- J - 1
if (L<=0) {
L <- 0
break()
}
}
# Finding right bound
while (K > 0 & y < prob_conc(R, p.shape, Q, n.tab, dsct)) {
R <- R + sl.size
K <- K - 1
}
return(c(L,R))
}
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.1, 25)
mc
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.01, 25)
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.001, 25)
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.0001, 25)
xv <- seq(5.2,5.3, by=0.01)
xv
xv <- seq(5.2,5.3, by=0.001)
xv
yv <- rep(0, length(xv))
xv <- seq(5.2,5.3, by=0.001)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], p.shape, Q, n.tab, dsct)
}
xv <- seq(5.2,5.3, by=0.001)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], 10, Q, c(50,50,50), 0.5)
}
plot(xv, yv, type="l")
xv <- seq(5.2,10, by=0.01)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], 10, Q, c(50,50,50), 0.5)
}
xv <- seq(5.2,10, by=0.01)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], 10, Q, c(50,50,50), 0.5)
}
plot(xv, yv, type="l")
xv <- seq(100,200, by=0.01)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], 10, Q, c(50,50,50), 0.5)
}
plot(xv, yv, type="l")
?lgamma
prob_conc <- function(conc, p.shape, Q, n.tab, dsct) {
log_prob <- -conc*Q+(p.shape-1)*log(conc)
log_prob <- log_prob + sum(lgamma(n.tab+conc/dsct) - lgamma(conc/dsct))
return(log_prob)
}
y.slice <- runif(1, 0, prob_conc(mc, 10, Q, c(50,50,50), 0.5))
mc
y.slice
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.1, 50)
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.01, 50)
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.001, 50)
xv <- seq(5,6, by=0.01)
xv
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], 10, Q, c(50,50,50), 0.5)
}
plot(xv, yv, type="l")
xv <- seq(0,10, by=0.1)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], 10, Q, c(50,50,50), 0.5)
}
plot(xv, yv, type="l")
mc <- map_conc(3, 10, Q, c(50,50,50), 0.5)
mc
mc <- map_conc(mc, 10, Q, c(50,50,50), 0.5)
mc
mc <- map_conc(mc, 10, Q, c(50,50,50), 0.5)
mc
mc <- map_conc(3, 10, Q, c(50,50,50), 0.5)
mc
find_bounds(mc, y.slice, 10, Q, c(50,50,50), 0.5, 0.001, 1000)
digamma(c(1,2,3))
mc
mc/3
mc/2.1
gc()
source('~/Documents/repositories/battiston_sampler/R/b_sampler.R', echo=TRUE)
conc <- 3
p.shape <- 10
Q <- 1/2 - sum(log(q))
q <- rbeta(conc, rep(1000,3))
q <- rbeta(3, conc, rep(1000,3))
q
Q <- 1/2 - sum(log(q))
Q
n.tba <- c(50,50,50)
dsct <- 0.5
mc <- map_conc(conc, p.shape, Q, n.tab, dsct)
n.tab <- c(50,50,50)
rm(n.tba)
mc <- map_conc(conc, p.shape, Q, n.tab, dsct)
mc
xv <- seq(0,10, by=0.1)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], p.shape, Q, n.tab, dsct)
}
xv[i]
p.shape
Q
n.tab
dsct
debugSource('~/Documents/repositories/battiston_sampler/R/b_sampler.R', echo=TRUE)
n.tab
conc
n.tab+conc/dsct
lgamma(n.tab+conc/dsct)
lgamma(0)
source('~/Documents/repositories/battiston_sampler/R/b_sampler.R', echo=TRUE)
iter <- 50
iter <- 50
mc <- 1
for (i in 1:iter) {
mc <- map_conc(mc, p.shape, Q, n.tab, dsct)
}
mc
mc <- c(1, rep(0, iter-1))
mc
iter <- 50
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
plot(mc, type="l")
prob_conc(4.985675, p.shape, Q, n.tab, dsct)
map_conc(4.985675, p.shape, Q, n.tab, dsct)
Q <- 1/2 + sum(log(q))
Q
iter <- 50
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
Q <- 1/2 - sum(log(q))
iter <- 50
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
gc()
conc <- 50
p.shape <- 5
n.tab <- c(20,20,20)
dsct <- 0.2
q <- rbeta(3, conc, 500)
q
Q <- 1/2 - sum(log(q))
Q
source('~/Documents/repositories/battiston_sampler/R/b_sampler.R', echo=TRUE)
mc
xv <- seq(1,50, by=1)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], p.shape, Q, n.tab, dsct)
}
plot(xv, yv, type="l")
xv <- seq(0.1,10, by=0.1)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], p.shape, Q, n.tab, dsct)
}
plot(xv, yv, type="l")
mc
map_conc <- function(conc, p.shape, Q, n.tab, dsct) {
J <- length(n.tab)
p <- sum(digamma(n.tab+conc/dsct)-digamma(conc/dsct))
p <- p/J + dsct*(p.shape-1)/(conc*J) - dsct*Q/J
return(dsct*inv_digamma(p))
}
iter <- 50
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
map_conc <- function(conc, p.shape, Q, n.tab, dsct) {
J <- length(n.tab)
p <- sum(digamma(n.tab+conc/dsct))
p <- p/J + dsct*(p.shape-1)/(conc*J) - dsct*Q/J
return(dsct*inv_digamma(p))
}
iter <- 50
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
optim(list(1), prob_conc, p.shape=p.shape, Q=Q, n.tab=n.tab, dsct=dsct)
warnings()
?optim
optimize(list(1), prob_conc, p.shape=p.shape, Q=Q, n.tab=n.tab, dsct=dsct)
optimize(1, prob_conc, p.shape=p.shape, Q=Q, n.tab=n.tab, dsct=dsct)
?optimize
optimize(prob_conc, interval=(0,10), p.shape=p.shape, Q=Q, n.tab=n.tab, dsct=dsct)
optimize(prob_conc, interval=c(0,10), p.shape=p.shape, Q=Q, n.tab=n.tab, dsct=dsct)
prob_conc <- function(conc, p.shape, Q, n.tab, dsct) {
log_prob <- -conc*Q+(p.shape-1)*log(conc)
log_prob <- log_prob + sum(lgamma(n.tab+conc/dsct) - lgamma(conc/dsct))
return(-log_prob)
}
optimize(prob_conc, interval=c(0,10), p.shape=p.shape, Q=Q, n.tab=n.tab, dsct=dsct)
digamma(inv_digamma(6))
digamma(inv_digamma(10))
iter <- 50
mc <- c(10, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
mc <- c(100, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
mc <- c(0.001, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
mc <- c(0.1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
n.tab
gc()
conc <- 1
p.shape <- 1
q <- rbeta(3, conc, rep(50, 3))
q
Q <- 1/2 - sum(log(q))
Q
n.tab <- rep(1, 3)
n.tab
dsct <- 0.1
#' HPY sampler from Battiston et al. (2018)
#'
#' @param Y Matrix of taxa counts (rows are populations, columns are species)
#' @param n.iter Number of MCMC iterations (after burn-in)
#' @param quiet If TRUE, console output is suppressed
#' @param n.burn Number of burn-in iterations
#'
#' @return
#' @export
#'
#' @examples
b_sampler <- function(Y, n.iter, n.burn, quiet=FALSE) {
if (!is.numeric(Y) | !is.matrix(Y) |
any(Y<0) | any(Y!=floor(Y))) stop("Y must be a numeric matrix of positive counts")
J <- NROW(Y)
K <- NCOL(Y) # Number of distinct species in joint sample
# Initializing PY parameters
gamma <- 3 # Top-level concentation
alpha <- 0.8 # Top-level discount
theta <- rep(1000, J) # Population-level concentration
sigma <- rep(0.5, J) # Population-level discount
# Initializing table info
sp.vec <- vector("list", length=J)
n <- rowSums(Y) # The number of individuals in each population
tab <- vector("list", length=J) # List to hold table indicators for each population
t.c <- vector("list", length=J) # Table counts (and species corresponding to each table)
n.tab <- rep(0, J) # Number of tables in each population
n.s.tab <- matrix(1, J, K) # Number of tables for a given species in each population
for (j in 1:J) {
# Initially one table for each species
sp.vec[[j]] <- rep(1:K, Y[j,])
tab[[j]] <- rep(1:sum(Y[j,]>0), Y[j,][Y[j,]>0])
t.c[[j]] <- cbind((1:K)[Y[j,]>0], Y[j,][Y[j,]>0])
n.tab[j] <- NROW(t.c[[j]])
}
gamma.s <- rep(0, n.iter)
alpha.s <- rep(0, n.iter)
theta.s <- matrix(0, n.iter, J)
sigma.s <- matrix(0, n.iter, J)
n.tab.s <- matrix(0, n.iter, J)
n.s.tab.s <- array(0, dim=c(n.iter, J, K))
# Loop over MCMC iterations
for (i in 1:(n.burn+n.iter)) {
idx <- i - n.burn
if (!quiet & i==1) cat("Beginning burn-in:", "\n")
if (!quiet & i==n.burn+1) cat("Beginning sampling:", "\n")
if (!quiet & i%%100==0) cat(" ", i, "\n")
# Loop over populations
for (j in 1:J) {
# Loop over individuals in a population
for (p in 1:n[j]){
sp.cur <- sp.vec[[j]][p]
# Remove current individual from its table
t.cur <- tab[[j]][p]
t.c[[j]][t.cur,2] <- t.c[[j]][t.cur,2] - 1
if (t.c[[j]][t.cur,2]==0) {
# Drop table and make adjustments
t.c[[j]] <- t.c[[j]][-t.cur,]
tab[[j]][tab[[j]]>t.cur] <- tab[[j]][tab[[j]]>t.cur] - 1
n.tab[j] <- n.tab[j] - 1
n.s.tab[j, sp.cur] <- n.s.tab[j, sp.cur] - 1
}
# Reassign individual to new or existing table
#new.t <- (theta[j]+n.tab[j]*sigma[j])*(sum(n.s.tab[,sp.cur])-alpha)/
#          ((theta[j]+n[j]-1)*(gamma+sum(n.tab)))
#prob.unsc <- c(freq.t, new.t)
num <- (theta[j]+n.tab[j]*sigma[j])*(sum(n.s.tab[, sp.cur])-alpha)
den <- (gamma+sum(n.tab))*(Y[j,sp.cur]-1-n.s.tab[j, sp.cur]*sigma[j]) +
(theta[j]+n.tab[j]*sigma[j])*(sum(n.s.tab[,sp.cur])-alpha)
is.new <- rbinom(1, 1, num/den)
#if (is.na(is.new)) browser()
if (is.new) {
# Allocate new table
t.c[[j]] <- rbind(t.c[[j]], c(sp.cur, 1))
n.tab[j] <- n.tab[j] + 1
n.s.tab[j, sp.cur] <- n.s.tab[j, sp.cur] + 1
tab[[j]][p] <- n.tab[j]
} else {
# Sample existing table (from proper species)
freq.t <- ifelse(t.c[[j]][,1]==sp.cur, (t.c[[j]][,2]-sigma[j])/(theta[j]+n[j]-1), 0)
wh.t <- sample(1:length(freq.t), 1, prob=freq.t)
t.c[[j]][wh.t, 2] <- t.c[[j]][wh.t, 2] + 1
tab[[j]][p] <- wh.t
}
}
# Sample local-level PY parameters
s.local <- py_local(theta[j], sigma[j])
theta[j] <- s.local$theta
sigma[j] <- s.local$sigma
if (i>n.burn) {
theta.s[idx,j] <- theta[j]
sigma.s[idx,j] <- sigma[j]
n.tab.s[idx,j] <- n.tab[j]
}
}
# Sample top-level PY parameters
s.top <- py_top(gamma, alpha)
gamma <- s.top$gamma
alpha <- s.top$alpha
if (i>n.burn) {
gamma.s[idx] <- gamma
alpha.s[idx] <- alpha
n.s.tab.s[idx,,] <- n.s.tab
}
}
return(list(gamma=gamma.s, alpha=alpha.s, theta=theta.s, sigma=sigma.s,
tab=tab, t.c=t.c, n.tab=n.tab.s, n.s.tab=n.s.tab.s))
}
# TODO
py_local <- function(theta.c, sigma.c) {
theta <- theta.c
sigma <- sigma.c
return(list(theta=theta, sigma=sigma))
}
# TODO
py_top <- function(gamma.c, alpha.c) {
gamma <- gamma.c
alpha <- alpha.c
return(list(gamma=gamma, alpha=alpha))
}
#' Sample the concentration parameter hierarchical in Pitman-Yor process
#'
#' @param conc Current value of the concentration parameter
#' @param J Number of populations
#' @param n
#'
#' @return
#' @export
#'
#' @examples
samp_conc <- function(conc, p.shape, p.scale, n.tab, n, dsct) {
# Sample auxiliary Beta variables
q <- rbeta(length(n), conc, n)
Q <- 1/p.scale - sum(log(q))
conc.map <- map_conc(conc, p.shape, Q, n.tab, dsct)
conc <- slice_conc(conc.map, p.shape, Q, n.tab, dsct)
return(conc)
}
#' Inverse digamma function
#'
#' @param x The value at which to evaluate the inverse of the digamma function
#'
#' @return The inverse of the digamma function evaluated at x
#' @export
#'
#' @examples
inv_digamma <- function(x) {
if (x<(-2.22)) {
g <- -1/(x-digamma(1))
} else {
g <- exp(x)+0.5
}
for(i in 1:4) {
g <- g - (digamma(x)-x)/trigamma(x)
}
return(g)
}
map_conc <- function(conc, p.shape, Q, n.tab, dsct) {
J <- length(n.tab)
p <- sum(digamma(n.tab+conc/dsct))
p <- p/J + dsct*(p.shape-1)/(conc*J) - dsct*Q/J
return(dsct*inv_digamma(p))
}
prob_conc <- function(conc, p.shape, Q, n.tab, dsct) {
log_prob <- -conc*Q+(p.shape-1)*log(conc)
log_prob <- log_prob + sum(lgamma(n.tab+conc/dsct) - lgamma(conc/dsct))
return(log_prob)
}
# Slice sample procedure based on Neal 2003
slice_conc <- function(conc.map, p.shape, Q, n.tab, dsct, sl.size, max.size) {
y.slice <- runif(1, 0, prob_conc(conc.map, p.shape, Q, n.tab, dsct))
bounds <- find_bounds(y, p.shape, Q, n.tab, dsct, sl.size, max.size)
samp <- runif(1, bounds[1], bounds[2])
if (TRUE) {
# ACCEPT
} else {
# REJECT AND TRY AGAIN
}
return(samp)
}
# Find the bounds of a slice
find_bounds <- function(conc.map, y, p.shape, Q, n.tab, dsct, sl.size, max.size) {
U <- runif(1)
V <- runif(1)
L <- conc.map - sl.size*U
R <- L + sl.size
J <- floor(max.size*V)
K <- (max.size - 1) - J
# Finding left bound
while (J > 0 & y < prob_conc(L, p.shape, Q, n.tab, dsct)) {
L <- L - sl.size
J <- J - 1
if (L<=0) {
L <- 0
break()
}
}
# Finding right bound
while (K > 0 & y < prob_conc(R, p.shape, Q, n.tab, dsct)) {
R <- R + sl.size
K <- K - 1
}
return(c(L,R))
}
iter <- 50
mc <- c(1, rep(0, iter-1))
for (i in 2:iter) {
mc[i] <- map_conc(mc[i-1], p.shape, Q, n.tab, dsct)
}
mc
xv <- seq(0.1,10, by=0.1)
yv <- rep(0, length(xv))
for (i in 1:length(xv)) {
yv[i] <- prob_conc(xv[i], p.shape, Q, n.tab, dsct)
}
plot(xv, yv, type="l")
install.packages("mBPCR")
install.packages("misreport")
library(misreport)
logAdd
misreport::logAdd
double(9)
as.double(454)
dyn.load("C/stirling.so")
.C("stirling", tab = matrix(0,3,3), N = 3, M = 3)
dyn.load("C/stirling.so")
.C("stirling", tab = matrix(0,3,3), N = 3, M = 3)
.C("stirling", tab = matrix(0,3,3), N = 4, M = 4)
dyn.unload("C/stirling.so")
.C("stirling", tab = matrix(0,3,3), N = 4, M = 4)
dyn.load("C/stirling.so")
.C("stirling", tab = matrix(0,3,3), N = 4, M = 4)
dyn.load("C/stirling.so")
.Call("add", 1, 2)
.Call("add", 565, 568)
dyn.load("C/stirling.so")
.Call("stirling", 25, 24)
